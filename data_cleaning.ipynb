{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b6556f-db42-4f52-ac73-98a102c98937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "extracted_data_fname = 'product_raw_data_2023-11-20.csv'\n",
    "raw_data_df = pd.read_csv(extracted_data_fname)\n",
    "\n",
    "# Remove all trailers and lowercase all string\n",
    "raw_data_df = raw_data_df.apply(lambda x: x.str.lower().str.strip() if x.dtype == 'object' else x)\n",
    "\n",
    "# Clean the product_name column\n",
    "raw_data_df['product_name'] = raw_data_df['product_name'].astype(object) # Specify the datatype as object\n",
    "raw_data_df = raw_data_df[raw_data_df['product_name'].notnull()] # product_name field should have no null values\n",
    "\n",
    "# Clean the product_name column\n",
    "raw_data_df['product_name'] = raw_data_df['product_name'].astype(object) # Specify the datatype as object\n",
    "raw_data_df = raw_data_df[raw_data_df['product_name'].notnull()] # product_name field should have no null values\n",
    "\n",
    "regex_volume = re.compile(r'(\\d+cl|\\d+ml|\\d+l|\\d+.liter|\\d+.ml|\\d+.cl)') # Look for volume on product_name\n",
    "\n",
    "raw_data_df['volume'] = raw_data_df['product_name'].str.extractall(regex_volume).astype(str).groupby(level=0).agg(','.join) # Create another column for volume and concatenate them if volume variety is more than 1\n",
    "\n",
    "raw_data_df['product_name'] = raw_data_df['product_name'].apply(lambda x: regex_volume.sub('', x)) # remove volumes on the product_name column\n",
    "\n",
    "# Add column freebies since some products has freebies\n",
    "regex_freebie = re.compile(r'(with.+|w/.+|free.*|.*not for sale.*)')\n",
    "raw_data_df['freebie'] = raw_data_df['product_name'].str.extract(regex_freebie).astype(str).groupby(level=0).agg(','.join) # Create another column for volume and concatenate them if freebies variety is more than 1\n",
    "raw_data_df['product_name'] = raw_data_df['product_name'].apply(lambda x: regex_freebie.sub('', x)) # remove freebies on the product_name column\n",
    "\n",
    "regex_gift = re.compile(r'(festive gift.+|gift .+|gifting kit)') \n",
    "raw_data_df['gift_set'] = raw_data_df['product_name'].str.extract(regex_gift).astype(str).groupby(level=0).agg(','.join) # Create another column for gift_set\n",
    "raw_data_df['product_name'] = raw_data_df['product_name'].apply(lambda x: regex_gift.sub('', x)) # remove gift sets on product_name_column\n",
    "\n",
    "regex_limited = re.compile(r'(select limited edition gift packaging|edition moira gift box|limited.+)') \n",
    "raw_data_df['limited_edition'] = raw_data_df['product_name'].str.extract(regex_limited).astype(str).groupby(level=0).agg(','.join) # Create another column for limited edition\n",
    "raw_data_df['product_name'] = raw_data_df['product_name'].apply(lambda x: regex_limited.sub('', x)) # remove limited edition on product_name_column\n",
    "\n",
    "raw_data_df['product_name'] = raw_data_df['product_name'].str.replace('[^a-z0-9\\s%.]', '', regex = True) # Remove special characters except % and .\n",
    "raw_data_df = raw_data_df.apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
    "\n",
    "raw_data_df['product_name'] = raw_data_df['product_name'].replace('', 'not for sale') # after removing freebies on the column some has become empty strings since it is not for sale.\n",
    "\n",
    "raw_data_df.loc[raw_data_df['product_name'] == 'chivas regal 12 year old blended scotch whisky', 'product_name'] = 'chivas regal 12 years old blended scotch whisky'\n",
    "raw_data_df.loc[raw_data_df['product_name'] == 'maria clara .', 'product_name'] = 'maria clara'\n",
    "\n",
    "\n",
    "# Extract brand name on product_name column Using fuzzy partial_ratio\n",
    "# Remove special charactes on brand\n",
    "raw_data_df['brand'] = raw_data_df['brand'] = raw_data_df['brand'].str.replace('[^a-z0-9\\s]', '', regex = True) # Remove special characters except % and .\n",
    "\n",
    "existing_brands = raw_data_df['brand'].unique() # get the unique value for the brand column\n",
    "additional_brands = pd.read_csv('alcohol_brand_names.csv') # import available data set online for liquor brands all over the world. add brand if needed\n",
    "additional_brands['Brand_Name'] = additional_brands['Brand_Name'].str.lower() # Make sure the brands are in lower case\n",
    "\n",
    "# Check if additional_brands is empty\n",
    "if not additional_brands.empty:\n",
    "    combined_unique_brands = pd.unique(pd.concat([pd.Series(existing_brands), additional_brands['Brand_Name']]))\n",
    "else:\n",
    "    combined_unique_brands = existing_brands\n",
    "\n",
    "products = raw_data_df['product_name']\n",
    "\n",
    "\n",
    "best_matches = []\n",
    "scores = []\n",
    "\n",
    "for product in products:\n",
    "    # Convert each brand to string to handle non-string elements\n",
    "    brand_str = [str(combined_unique_brand) for combined_unique_brand in combined_unique_brands]\n",
    "\n",
    "    # Find the best match for the current product in the list of brands using partial_ratio\n",
    "    result = process.extractOne(product, brand_str, scorer=fuzz.partial_ratio)\n",
    "\n",
    "    # The result is a tuple with the best match and its score\n",
    "    best_match, score = result\n",
    "\n",
    "    # Append the results to the lists\n",
    "    best_matches.append(best_match)\n",
    "    scores.append(score)\n",
    "\n",
    "# Add the lists as new columns to the DataFrame\n",
    "raw_data_df['best_brand_match'] = best_matches\n",
    "raw_data_df['similarity_score'] = scores\n",
    "\n",
    "# Update the 'brand' column based on the matching result if the 'brand' is null and the score is greater than or equal to 89\n",
    "condition = (raw_data_df['brand'].isna()) & (raw_data_df['similarity_score'] >= 89) # adjust the similarity score as needed\n",
    "raw_data_df.loc[condition, 'brand'] = raw_data_df.loc[condition, 'best_brand_match']\n",
    "\n",
    "# Drop the colulumn best_brand_match and similarity_score\n",
    "raw_data_df.drop(['best_brand_match', 'similarity_score'], axis=1, inplace=True)\n",
    "\n",
    "# Check if 'brand' is null and fill with 'unknown brand'\n",
    "raw_data_df['brand'].fillna('unknown brand', inplace=True)\n",
    "\n",
    "# Change the datatype of extraction_date column fro object to datetime\n",
    "raw_data_df['extraction_date'] = pd.to_datetime(raw_data_df['extraction_date'])\n",
    "\n",
    "# split volume into two columns volume_quantity and volume_unit\n",
    "raw_data_df['volume'] = raw_data_df['volume'].str.replace(\" \", \"\")\n",
    "regex_volume_unit =  re.compile(r'(\\d+)\\s*([a-zA-Z]+)')\n",
    "matches = raw_data_df['volume'].str.extractall(regex_volume_unit)\n",
    "\n",
    "# Assign the results to separate columns\n",
    "raw_data_df['volume_quantity'] = matches[0].astype(str).groupby(level=0).agg(','.join)\n",
    "raw_data_df['volume_unit'] = matches[1].astype(str).groupby(level=0).agg(','.join)\n",
    "\n",
    "# Drop the column volume\n",
    "raw_data_df.drop(['volume'], axis=1, inplace=True)\n",
    "\n",
    "# remove special characters and headers, trailers on frebie column\n",
    "raw_data_df['freebie'] = raw_data_df['freebie'].str.replace('[^a-z0-9\\s&/]', '', regex = True) # Remove special characters except & and /\n",
    "raw_data_df['freebie'] = raw_data_df['freebie'].str.strip()\n",
    "\n",
    "# remove special characters and headers, trailers on gift_set column\n",
    "raw_data_df['gift_set'] = raw_data_df['gift_set'].str.replace('[^a-z0-9\\s]', '', regex = True) # Remove all special characters \n",
    "raw_data_df['gift_set'] = raw_data_df['gift_set'].str.strip()\n",
    "\n",
    "# remove special characters and headers, trailers onv limited_edition column\n",
    "raw_data_df['limited_edition'] = raw_data_df['limited_edition'].str.replace('[^a-z0-9\\s%]', '', regex = True) # Remove all special characters except % \n",
    "raw_data_df['limited_edition'] = raw_data_df['limited_edition'].str.strip()\n",
    "\n",
    "# replace all null values as nan\n",
    "null_values = [None, 'NA', '', \"['']\", 'nan']\n",
    "raw_data_df = raw_data_df.replace(null_values, np.nan)\n",
    "\n",
    "# remove special characters except ','\n",
    "raw_data_df['variation'] = raw_data_df['variation'].str.replace('[^a-z0-9\\s,]', '', regex = True) \n",
    "\n",
    "\n",
    "# import raw_data_df as sqlite for database flat/wide table design\n",
    "cleaning_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "db_clean_filename = f\"product_clean_data_{datetime.now().strftime('%Y-%m-%d')}.db\"\n",
    "conn = sqlite3.connect(db_clean_filename) # Connect to SQLite db\n",
    "\n",
    "# specify the olumn data types \n",
    "column_data_types = {\n",
    "    \"unique_item_id\": \"INTEGER PRIMARY KEY\",\n",
    "    \"product_name\": \"TEXT\",\n",
    "    \"current_stock\": \"INTEGER\",\n",
    "    \"shop_name\": \"TEXT\",\n",
    "    \"shop_id\": \"INTEGER\",\n",
    "    \"brand\": \"TEXT\",\n",
    "    \"sold_per_month\": \"INTEGER\",\n",
    "    \"historical_sold\": \"INTEGER\",\n",
    "    \"liked_count\": \"NUMERIC\",\n",
    "    \"variation_type\": \"TEXT\",\n",
    "    \"variation\": \"TEXT\",\n",
    "    \"current_price\": \"NUMERIC\",\n",
    "    \"min_price\": \"NUMERIC\",\n",
    "    \"max_price\": \"NUMERIC\",\n",
    "    \"lowest_price_guarantee\": \"INTEGER\",\n",
    "    \"current_discount\": \"NUMERIC\",\n",
    "    \"rating_star\": \"NUMERIC\",\n",
    "    \"shopee_verified\": \"INTEGER\",\n",
    "    \"official_shop\": \"INTEGER\",\n",
    "    \"cc_installment\": \"INTEGER\",\n",
    "    \"none_cc_installment\": \"INTEGER\",\n",
    "    \"preferred_seller\": \"INTEGER\",\n",
    "    \"shop_location\": \"TEXT\",\n",
    "    \"shop_rating\": \"NUMERIC\",\n",
    "    \"cod\": \"TEXT\",\n",
    "    \"extraction_date\": \"TEXT\",\n",
    "    \"freebie\": \"TEXT\",\n",
    "    \"gift_set\": \"TEXT\",\n",
    "    \"limited_edition\": \"TEXT\",\n",
    "    \"volume_quantity\": \"NUMERIC\",\n",
    "    \"volume_unit\": \"TEXT\",\n",
    "}\n",
    "\n",
    "raw_data_df.to_sql(db_clean_filename, conn, index=False, if_exists='replace', dtype=column_data_types) # save to sql database\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852f87e-170a-48d4-8774-8ac338b8e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df.to_excel('initial_cleaning_v22_partial_ratio_v11.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc78b3-2691-40f4-a7aa-0c89ab674d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_rows', None)     # Display all rows\n",
    "pd.set_option('display.max_colwidth', None) # Display full column width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06e8a1-ee34-4e4d-9a28-bf644153ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Done. Total of {len(raw_data_df)} rows updated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbafc7c1-32c0-4009-b213-b29f852e1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df['extraction_date'] = pd.to_datetime(raw_data_df['extraction_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed4343-6087-4240-aaa2-f5d3b1b51529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of possible brand_names\n",
    "brand_names_re= re.compile(r'('bacardi'|'emperador'|'imperial'|'jameson'|'suntory'|'smokehead'|'glenmorangie'|'bottega|)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a69583a-2d64-4e69-a986-0e6aefd7600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_brands = pd.read_csv('alcohol_brand_names.csv')\n",
    "additional_brands['Brand_Name'] = additional_brands['Brand_Name'].str.lower() # Make sure the brands are in lower case\n",
    "\n",
    "# Check if additional_brands is empty\n",
    "if not additional_brands.empty:\n",
    "    combined_unique_brands = pd.unique(pd.concat([pd.Series(existing_brands), additional_brands['Brand_Name']]))\n",
    "else:\n",
    "    combined_unique_brands = existing_brands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b9cf0-c803-4197-bbf7-e738b8249426",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_unique_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62a191-e05c-4ca9-a1da-bfa26d4c1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedeb178-cbbf-477b-b698-1e95c3b2b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split volume into two columns volume_quantity and volume_unit\n",
    "raw_data_df['volume'] = raw_data_df['volume'].str.replace(\" \", \"\")\n",
    "regex_volume_unit =  re.compile(r'(\\d+)\\s*([a-zA-Z]+)')\n",
    "matches = raw_data_df['volume'].str.extractall(regex_volume_unit)\n",
    "\n",
    "# Assign the results to separate columns\n",
    "raw_data_df['volume_quantity'] = matches[0].astype(str).groupby(level=0).agg(','.join)\n",
    "raw_data_df['volume_unit'] = matches[1].astype(str).groupby(level=0).agg(','.join)\n",
    "\n",
    "# Drop the column volume\n",
    "raw_data_df.drop(['volume'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40db17-d989-403e-9dde-d10354c17e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df['volume_unit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ddfb4d-7a05-45a5-8fd5-5d6357676f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all null values as nan\n",
    "null_values = [None, 'NA', '', \"['']\"]\n",
    "raw_data_df = raw_data_df.replace(null_values, np.nan)\n",
    "\n",
    "# remove special characters except ','\n",
    "raw_data_df['variation'] = raw_data_df['variation'].str.replace('[^a-z0-9\\s,]', '', regex = True) \n",
    "raw_data_df[raw_data_df['variation'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55babfe2-7542-4d15-b372-7c42c90b5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df[raw_data_df['freebie'].isna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
